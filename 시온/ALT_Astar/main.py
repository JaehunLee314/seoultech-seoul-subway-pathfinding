"""
A* ìµœë‹¨ì‹œê°„ íƒìƒ‰ (ì„œìš¸ ì§€í•˜ì²  1~5í˜¸ì„ )
- íœ´ë¦¬ìŠ¤í‹±: ALT (Landmarks + Triangle inequality)

ì‚¬ìš©ë²• (CLI)
$ python astar_alt_full.py
ì¶œë°œì—­ ì´ë¦„: ì„œìš¸ì—­
ë„ì°©ì—­ ì´ë¦„: ìž ì‹¤
... ê²°ê³¼ ì¶œë ¥ ...

Notes
-----
* ì²« ì‹¤í–‰ ì‹œ 12ê°œ ëžœë“œë§ˆí¬ì—ì„œ ëª¨ë“  ë…¸ë“œê¹Œì§€ì˜ ìµœë‹¨ê±°ë¦¬(ì‹œê°„)ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
  ì•½ 1~2ì´ˆ(1ë§Œ ë…¸ë“œ ë¯¸ë§Œ) ì •ë„ ì†Œìš”ë˜ë©°, ì´í›„ ì¿¼ë¦¬ì—ì„œëŠ” ë©”ëª¨ë¦¬ lookup ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
* landmark_dist.pkl íŒŒì¼ì´ ì¡´ìž¬í•˜ë©´ ì „ì²˜ë¦¬ë¥¼ ê±´ë„ˆë•ë‹ˆë‹¤.
"""

from __future__ import annotations
import os, pickle, math, heapq, glob, time
from collections import defaultdict, deque
from typing import Dict, Tuple, List
import pandas as pd
import numpy as np
import random

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0.  ë…¸ì„  ì •ì˜ (1~5í˜¸ì„ ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  â–¶ ê¸°ì¡´ ALT_Astar.py ì˜ ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë³µë¶™í–ˆìŠµë‹ˆë‹¤.
#  â–¶ â€¦(ê¸¸ì–´ì„œ ìƒëžµ) ëª©ë¡ì€ ë™ì¼í•˜ë¯€ë¡œ ë³¸ íŒŒì¼ë§Œìœ¼ë¡œ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.
line1_stations = {
    "trunk": [
        "ì†Œìš”ì‚°","ë™ë‘ì²œ","ë³´ì‚°","ë™ë‘ì²œì¤‘ì•™","ì§€í–‰","ë•ì •","ë•ê³„","ì–‘ì£¼","ë…¹ì–‘","ê°€ëŠ¥","ì˜ì •ë¶€",
        "íšŒë£¡","ë§ì›”ì‚¬","ë„ë´‰ì‚°","ë„ë´‰","ë°©í•™","ì°½ë™","ë…¹ì²œ","ì›”ê³„","ì„±ë¶","ì„ê³„","ì‹ ì´ë¬¸",
        "ì™¸ëŒ€ì•ž","íšŒê¸°","ì²­ëŸ‰ë¦¬","ì œê¸°ë™","ì‹ ì„¤ë™","ë™ë¬˜ì•ž","ë™ëŒ€ë¬¸","ì¢…ë¡œ5ê°€","ì¢…ë¡œ3ê°€","ì¢…ê°",
        "ì‹œì²­","ì„œìš¸ì—­","ë‚¨ì˜","ìš©ì‚°","ë…¸ëŸ‰ì§„","ëŒ€ë°©","ì‹ ê¸¸","ì˜ë“±í¬","ì‹ ë„ë¦¼","êµ¬ë¡œ",
        "ê°€ì‚°ë””ì§€í„¸ë‹¨ì§€","ë…ì‚°","ê¸ˆì²œêµ¬ì²­","ì„ìˆ˜","ê´€ì•…","ì•ˆì–‘","ëª…í•™","ê¸ˆì •","êµ°í¬","ë‹¹ì •",
        "ì˜ì™•","ì„±ê· ê´€ëŒ€","í™”ì„œ","ìˆ˜ì›","ì„¸ë¥˜","ë³‘ì ","ì„¸ë§ˆ","ì˜¤ì‚°ëŒ€","ì˜¤ì‚°","ì§„ìœ„","ì†¡íƒ„",
        "ì„œì •ë¦¬","ì§€ì œ","í‰íƒ","ì„±í™˜","ì§ì‚°","ë‘ì •","ì²œì•ˆ","ë´‰ëª…","ìŒìš©","ì•„ì‚°","ë°°ë°©",
        "ì˜¨ì–‘ì˜¨ì²œ","ì‹ ì°½"
    ],
    "incheon_branch": [
        "êµ¬ë¡œ","êµ¬ì¼","ê°œë´‰","ì˜¤ë¥˜ë™","ì˜¨ìˆ˜","ì—­ê³¡","ì†Œì‚¬","ë¶€ì²œ","ì¤‘ë™","ì†¡ë‚´","ë¶€ê°œ",
        "ë¶€í‰","ë°±ìš´","ë™ì•”","ê°„ì„","ì£¼ì•ˆ","ë„í™”","ì œë¬¼í¬","ë„ì›","ë™ì¸ì²œ","ì¸ì²œ"
    ],
    "gwangmyeong_branch": ["ê¸ˆì²œêµ¬ì²­","ê´‘ëª…"],
    "seodongtan_branch": ["ë³‘ì ","ì„¸ë§ˆ","ì„œë™íƒ„"]
}
line2_stations = {
    "main_loop": [
        "ì‹œì²­","ì„ì§€ë¡œìž…êµ¬","ì„ì§€ë¡œ3ê°€","ì„ì§€ë¡œ4ê°€","ë™ëŒ€ë¬¸ì—­ì‚¬ë¬¸í™”ê³µì›","ì‹ ë‹¹","ìƒì™•ì‹­ë¦¬",
        "ì™•ì‹­ë¦¬","í•œì–‘ëŒ€","ëšì„¬","ì„±ìˆ˜","ê±´ëŒ€ìž…êµ¬","êµ¬ì˜","ê°•ë³€","ìž ì‹¤ë‚˜ë£¨","ìž ì‹¤","ìž ì‹¤ìƒˆë‚´",
        "ì¢…í•©ìš´ë™ìž¥","ì‚¼ì„±","ì„ ë¦‰","ì—­ì‚¼","ê°•ë‚¨","êµëŒ€","ì„œì´ˆ","ë°©ë°°","ì‚¬ë‹¹","ë‚™ì„±ëŒ€",
        "ì„œìš¸ëŒ€ìž…êµ¬","ë´‰ì²œ","ì‹ ë¦¼","ì‹ ëŒ€ë°©","êµ¬ë¡œë””ì§€í„¸ë‹¨ì§€","ëŒ€ë¦¼","ì‹ ë„ë¦¼","ë¬¸ëž˜",
        "ì˜ë“±í¬êµ¬ì²­","ë‹¹ì‚°","í•©ì •","í™ëŒ€ìž…êµ¬","ì‹ ì´Œ","ì´ëŒ€","ì•„í˜„","ì¶©ì •ë¡œ"
    ],
    "seongsu_branch": ["ì„±ìˆ˜","ìš©ë‹µ","ì‹ ë‹µ","ìš©ë‘","ì‹ ì„¤ë™"],
    "sinjeong_branch": ["ì‹ ë„ë¦¼","ë„ë¦¼ì²œ","ì–‘ì²œêµ¬ì²­","ì‹ ì •ë„¤ê±°ë¦¬","ê¹Œì¹˜ì‚°"]
}
line3_stations = [
    "ëŒ€í™”","ì£¼ì—½","ì •ë°œì‚°","ë§ˆë‘","ë°±ì„","ëŒ€ê³¡","í™”ì •","ì›ë‹¹","ì›í¥","ì‚¼ì†¡","ì§€ì¶•","êµ¬íŒŒë°œ",
    "ì—°ì‹ ë‚´","ë¶ˆê´‘","ë…¹ë²ˆ","í™ì œ","ë¬´ì•…ìž¬","ë…ë¦½ë¬¸","ê²½ë³µê¶","ì•ˆêµ­","ì¢…ë¡œ3ê°€","ì„ì§€ë¡œ3ê°€",
    "ì¶©ë¬´ë¡œ","ë™ëŒ€ìž…êµ¬","ì•½ìˆ˜","ê¸ˆí˜¸","ì˜¥ìˆ˜","ì••êµ¬ì •","ì‹ ì‚¬","ìž ì›","ê³ ì†í„°ë¯¸ë„","êµëŒ€",
    "ë‚¨ë¶€í„°ë¯¸í„°ë„","ì–‘ìž¬","ë§¤ë´‰","ë„ê³¡","ëŒ€ì¹˜","í•™ì—¬ìš¸","ëŒ€ì²­","ì¼ì›","ìˆ˜ì„œ","ê°€ë½ì‹œìž¥",
    "ê²½ì°°ë³‘ì›","ì˜¤ê¸ˆ"
]
line4_stations = [
    "ì§„ì ‘ê´‘ë¦‰ìˆ²", "ì˜¤ë‚¨ì—­", "í’ì–‘ì—­", "ë³„ë‚´ë³„ê°€ëžŒì—­", "ë‹¹ê³ ê°œ","ìƒê³„","ë…¸ì›","ì°½ë™","ìŒë¬¸","ìˆ˜ìœ ","ë¯¸ì•„","ë¯¸ì•„ì‚¬ê±°ë¦¬","ê¸¸ìŒ","ì„±ì‹ ì—¬ëŒ€ìž…êµ¬",
    "í•œì„±ëŒ€ìž…êµ¬","í˜œí™”","ë™ëŒ€ë¬¸","ë™ëŒ€ë¬¸ì—­ì‚¬ë¬¸í™”ê³µì›","ì¶©ë¬´ë¡œ","ëª…ë™","íšŒí˜„","ì„œìš¸ì—­",
    "ìˆ™ëŒ€ìž…êµ¬","ì‚¼ê°ì§€","ì‹ ìš©ì‚°","ì´ì´Œ","ë™ìž‘","ì´ìˆ˜","ì‚¬ë‹¹","ë‚¨íƒœë ¹","ì„ ë°”ìœ„","ê²½ë§ˆê³µì›",
    "ëŒ€ê³µì›","ê³¼ì²œ","ì •ë¶€ê³¼ì²œì²­ì‚¬","ì¸ë•ì›","í‰ì´Œ","ë²”ê³„","ê¸ˆì •","ì‚°ë³¸","ìˆ˜ë¦¬ì‚°","ëŒ€ì•¼ë¯¸",
    "ë°˜ì›”","ìƒë¡ìˆ˜","í•œëŒ€ì•ž","ì¤‘ì•™","ê³ ìž”","ì´ˆì§€","ì•ˆì‚°","ì‹ ê¸¸ì˜¨ì²œ","ì •ì™•","ì˜¤ì´ë„"
]
line5_stations = {
    "main_line": [
        "ë°©í™”","ê°œí™”ì‚°","ê¹€í¬ê³µí•­","ì†¡ì •","ë§ˆê³¡","ë°œì‚°","ìš°ìž¥ì‚°","í™”ê³¡","ê¹Œì¹˜ì‚°","ì‹ ì •","ëª©ë™",
        "ì˜¤ëª©êµ","ì–‘í‰","ì˜ë“±í¬êµ¬ì²­","ì˜ë“±í¬ì‹œìž¥","ì‹ ê¸¸","ì—¬ì˜ë„","ì—¬ì˜ë‚˜ë£¨","ë§ˆí¬","ê³µë•","ì• ì˜¤ê°œ",
        "ì¶©ì •ë¡œ","ì„œëŒ€ë¬¸","ê´‘í™”ë¬¸","ì¢…ë¡œ3ê°€","ì„ì§€ë¡œ4ê°€","ë™ëŒ€ë¬¸ì—­ì‚¬ë¬¸í™”ê³µì›","ì²­êµ¬","ì‹ ê¸ˆí˜¸",
        "í–‰ë‹¹","ì™•ì‹­ë¦¬","ë§ˆìž¥","ë‹µì‹­ë¦¬","ìž¥í•œí‰","êµ°ìž","ì•„ì°¨ì‚°","ê´‘ë‚˜ë£¨","ì²œí˜¸","ê°•ë™",
        "ê¸¸ë™","êµ½ì€ë‹¤ë¦¬","ëª…ì¼","ê³ ë•","ìƒì¼ë™","ê°•ì¼","ë¯¸ì‚¬","í•˜ë‚¨í’ì‚°","í•˜ë‚¨ì‹œì²­","í•˜ë‚¨ê²€ë‹¨ì‚°"
    ],
    "macheon_branch": ["ê°•ë™","ë‘”ì´Œë™","ì˜¬ë¦¼í”½ê³µì›","ë°©ì´","ì˜¤ê¸ˆ","ê°œë¡±","ê±°ì—¬","ë§ˆì²œ"]
}

lines = {1: line1_stations, 2: line2_stations, 3: line3_stations, 4: line4_stations, 5: line5_stations}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. CSV ë¡œë“œ & ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_TRAVEL    = 2.0   # ì—­ê°„ ì£¼í–‰ ë°ì´í„° ì—†ì„ ë•Œ (ë¶„)
DWELL             = 0.5   # ì •ì°¨ (ë¶„)
FALLBACK_TRANSFER = 4.0   # í™˜ìŠ¹ ê¸°ë³¸ (ë¶„)

RUN_TIME_DIR      = "dataset/ì—­ê°„ì†Œìš”ì‹œê°„(ìˆ˜ìž‘ì—…)"
TRANSFER_CSV_PATH = "dataset/ì„œìš¸êµí†µê³µì‚¬_í™˜ìŠ¹ì—­ê±°ë¦¬ ì†Œìš”ì‹œê°„ ì •ë³´_20250331.csv"
COORD_CSV_PATH    = "dataset/station_location"
LM_CACHE_PATH     = "landmark_dist.pkl"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ìœ í‹¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _parse_mmss(txt: str) -> float | None:
    try:
        m, s = map(int, txt.split(":"))
        return m + s/60
    except Exception:
        return None

def load_run_times(folder: str = RUN_TIME_DIR) -> Dict[Tuple[str,str], float]:
    run = {}
    for p in glob.glob(os.path.join(folder, "*.csv")):
        df = pd.read_csv(p, encoding="utf-8")
        prev = None
        for _, row in df.iterrows():
            cur = str(row["ì—­ëª…"]).strip()
            t_raw = str(row["ì‹œê°„(ë¶„)"]).strip()
            t_val = _parse_mmss(t_raw)
            if t_val is None:
                prev = cur
                continue
            if prev:
                run[(prev,cur)] = run[(cur,prev)] = t_val
            prev = cur
    return run

def load_transfer_times(csv_path: str = TRANSFER_CSV_PATH):
    tbl = {}
    if not os.path.exists(csv_path):
        return tbl
    df = pd.read_csv(csv_path, encoding="cp949")
    for _, row in df.iterrows():
        ln1 = int(row["í˜¸ì„ "])              # ì˜ˆ: 2
        station = str(row["í™˜ìŠ¹ì—­ëª…"]).strip()
        digits = "".join(filter(str.isdigit, str(row["í™˜ìŠ¹ë…¸ì„ "])) )
        if not digits:
            continue
        ln2 = int(digits)
        t_val = _parse_mmss(str(row["í™˜ìŠ¹ì†Œìš”ì‹œê°„"]).strip())
        if t_val is None:
            continue
        tbl[((ln1,station),(ln2,station))] = tbl[((ln2,station),(ln1,station))] = t_val
    return tbl

def load_coords(folder_path=COORD_CSV_PATH):
    coords = {}
    for file in glob.glob(os.path.join(folder_path, "*.csv")):
        try:
            df = pd.read_csv(file, encoding="utf-8")
        except Exception as e:
            print(f"âš ï¸ CSV íŒŒì¼ {file} ì—´ê¸° ì‹¤íŒ¨: {e}")
            continue

        for _, row in df.iterrows():
            try:
                line_str = str(row["line"]).strip()
                if not line_str.endswith("í˜¸ì„ "):
                    continue
                ln = int(line_str.replace("í˜¸ì„ ", ""))
                station = str(row["station_name"]).strip()
                lat = float(row["latitude"])
                lon = float(row["longitude"])
                coords[(ln, station)] = (lat, lon)
            except Exception:
                continue  # í˜•ì‹ì´ ë§žì§€ ì•ŠëŠ” rowëŠ” ìŠ¤í‚µ
    return coords

def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(dlon/2)**2
    c = 2*math.atan2(math.sqrt(a), math.sqrt(1-a))
    return R*c

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ê·¸ëž˜í”„ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_graph(lines_dict, run_tbl, transfer_tbl):
    g = defaultdict(list)
    def add(u,v,w):
        g[u].append((w,v)); g[v].append((w,u))

    for ln, data in lines_dict.items():
        segments = data.values() if isinstance(data,dict) else [data]
        for key, seg in (data.items() if isinstance(data,dict) else [("linear",data)]):
            for a,b in zip(seg, seg[1:]):
                w = run_tbl.get((a,b), run_tbl.get((b,a), DEFAULT_TRAVEL)) + DWELL
                add((ln,a),(ln,b),w)
            if key.endswith("_loop"):
                a,b = seg[-1], seg[0]
                w = run_tbl.get((a,b), run_tbl.get((b,a), DEFAULT_TRAVEL)) + DWELL
                add((ln,a),(ln,b),w)

    # í™˜ìŠ¹ ê°„ì„ 
    station_to_lines = defaultdict(list)
    for ln, data in lines_dict.items():
        sts = (s for seg in data.values() for s in seg) if isinstance(data,dict) else data
        for st in sts:
            station_to_lines[st].append(ln)
    for st, lns in station_to_lines.items():
        for i in range(len(lns)):
            for j in range(i+1,len(lns)):
                u,v = (lns[i],st),(lns[j],st)
                w = transfer_tbl.get((u,v), FALLBACK_TRANSFER)
                add(u,v,w)
    return g

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Dijkstra (1 â†’ All) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def dijkstra(graph:dict, src) -> Dict[Tuple[int,str], float]:
    dist = {src:0.0}
    pq = [(0.0,src)]
    while pq:
        d,u = heapq.heappop(pq)
        if d>dist[u]:
            continue
        for w,v in graph[u]:
            nd = d+w
            if nd < dist.get(v,float('inf')):
                dist[v]=nd
                heapq.heappush(pq,(nd,v))
    return dist

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Landmark ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def choose_landmarks(graph:dict, k:int=12):
    # ê°„ë‹¨ ì „ëžµ: (1) ë…¸ë“œ degree ë†’ì€ ìˆœ, (2) ì„œë¡œ ë¨¼ ë…¸ë“œ ìš°ì„ 
    degrees = {n: len(graph[n]) for n in graph}
    sorted_nodes = sorted(degrees, key=degrees.get, reverse=True)
    landmarks=[]
    coord = COORDS
    for n in sorted_nodes:
        if n not in coord:  # ì¢Œí‘œ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ê±°ë¦¬ í‰ê°€ ë¶ˆê°€)
            continue
        lat1,lon1 = coord[n]
        # ê±°ë¦¬ê°€ ì¼ì • ì´ìƒ ë–¨ì–´ì§„ ë…¸ë“œë§Œ
        if all(haversine(lat1,lon1,*coord[lm])>10 for lm in landmarks):
            landmarks.append(n)
        if len(landmarks)>=k:
            break
    # ë§Œì•½ ë¶€ì¡±í•˜ë©´ degreeìˆœìœ¼ë¡œ ì±„ì›€
    for n in sorted_nodes:
        if len(landmarks)>=k:
            break
        if n not in landmarks and n in coord:
            landmarks.append(n)
    return landmarks

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. ë©”ì¸ (ì „ì²˜ë¦¬ & A*) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

RUN_TIMES      = load_run_times()
TRANSFER_TIMES = load_transfer_times()
COORDS         = load_coords()

graph = build_graph(lines, RUN_TIMES, TRANSFER_TIMES)
station_to_nodes = defaultdict(list)
for node in graph:
    station_to_nodes[node[1]].append(node)

# 6-1) Landmark distance table ë¡œë“œ or ê³„ì‚°
if os.path.exists(LM_CACHE_PATH):
    with open(LM_CACHE_PATH,"rb") as f:
        LANDMARKS, LM_DIST = pickle.load(f)
else:
    LANDMARKS = choose_landmarks(graph, k=12)
    LM_DIST = {L: dijkstra(graph, L) for L in LANDMARKS}
    with open(LM_CACHE_PATH,"wb") as f:
        pickle.dump((LANDMARKS,LM_DIST), f)

# 6-2) ALT íœ´ë¦¬ìŠ¤í‹±

def h_alt(node, goals:List[Tuple[int,str]]):
    # goals ëŠ” (í˜¸ì„ , ì—­) ë¦¬ìŠ¤íŠ¸ (ê°™ì€ ì—­ëª… ì—¬ëŸ¬ ë…¸ì„  ê°€ëŠ¥)
    best = 0.0
    for L in LANDMARKS:
        dL_node = LM_DIST[L].get(node, float('inf'))
        if dL_node==float('inf'):
            continue
        dL_goal_max = -1
        for g in goals:
            d = LM_DIST[L].get(g, float('inf'))
            if d!=float('inf'):
                dL_goal_max = max(dL_goal_max, abs(d - dL_node))
        if dL_goal_max>=0:
            best = max(best, dL_goal_max)
    # ALTê°€ ê³„ì‚° ë¶ˆê°€ëŠ¥í•œ rare ì¼€ì´ìŠ¤(ëžœë“œë§ˆí¬ì™€ ë‹¨ì ˆ) â†’ 0
    return best if best>0 else 0.0

# 6-3) A* search (ALT)

def astar(start_name:str, goal_name:str):
    if start_name not in station_to_nodes or goal_name not in station_to_nodes:
        raise ValueError("ì—­ ì´ë¦„ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
    goals = station_to_nodes[goal_name]

    SUPER = ('S','')
    graph[SUPER] = [(0,n) for n in station_to_nodes[start_name]]
    g_cost = {SUPER:0.0}
    parent = {SUPER:None}
    pq=[]
    for _,n in graph[SUPER]:
        g_cost[n]=0.0
        parent[n]=SUPER
        heapq.heappush(pq,(h_alt(n,goals),0.0,n))

    while pq:
        f,g,u = heapq.heappop(pq)
        if u in goals:
            path=[]
            cur=u
            while cur and cur!=SUPER:
                path.append(cur)
                cur=parent[cur]
            graph.pop(SUPER,None)
            return path[::-1], g
        if g>g_cost[u]:
            continue
        for w,v in graph[u]:
            ng=g+w
            if ng < g_cost.get(v,float('inf')):
                g_cost[v]=ng
                parent[v]=u
                heapq.heappush(pq,(ng+h_alt(v,goals), ng, v))
    graph.pop(SUPER,None)
    return None, float('inf')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ì¶œë ¥ ë³´ì¡° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def edge_time(u, v):
    for w, n in graph[u]:
        if n == v:
            return w
    return 0

def fmt_path(path):
    segs = []
    for i, (ln, st) in enumerate(path):
        if i == 0:
            segs.append(f"{ln}í˜¸ì„  {st}")
        else:
            prev = path[i - 1]
            segs.append(f" --{edge_time(prev, (ln, st)):.1f}ë¶„â†’ {ln}í˜¸ì„  {st}")
    return "".join(segs)

def generate_station_list():
    all_stations = set()

    def flatten_station_dict(d):
        for v in d.values():
            all_stations.update(v)

    flatten_station_dict(line1_stations)
    flatten_station_dict(line2_stations)
    all_stations.update(line3_stations)
    all_stations.update(line4_stations)
    flatten_station_dict(line5_stations)

    # âœ… í•­ìƒ ê°™ì€ ìˆœì„œë¡œ ì •ë ¬
    return sorted(list(all_stations))  # â† í•µì‹¬!

import time, random
import pandas as pd
import numpy as np

def analyse_1000_random_astar(all_stations, sample_count=100, repeats=30,
                              detail_csv="astar_runs.csv",
                              summary_csv="astar_summary.csv",
                              global_csv="global_summary.csv"):
    random.seed(42)
    # â¶ ìƒ˜í”Œ ìŒ ìƒì„±
    pairs = []
    seen = set()
    while len(pairs) < sample_count:
        s, g = random.sample(all_stations, 2)
        if (s, g) not in seen:
            pairs.append((s, g))
            seen.add((s, g))

    detail_records = []
    summary_records = []

    # â· ê° ìƒ˜í”Œë³„ ë°˜ë³µ ì‹¤í–‰ ë° summary ì¶œë ¥
    for i, (s, g) in enumerate(pairs, 1):
        times = []
        success = 0

        for r in range(1, repeats + 1):
            try:
                t0 = time.perf_counter()
                path, total = astar(s, g)
                t1 = time.perf_counter()
                if path:
                    elapsed = t1 - t0
                    times.append(elapsed)
                    success += 1
                    fmt = fmt_path(path)
                    detail_records.append({
                        "start": s, "goal": g, "run": r,
                        "elapsed_sec": round(elapsed, 6),
                        "total_min": round(total, 1),
                        "path": fmt
                    })
            except Exception:
                pass

        mean_sec  = float(np.mean(times)) if times else 0.0
        std_sec   = float(np.std(times))  if times else 0.0
        best_sec  = float(min(times))     if times else 0.0
        worst_sec = float(max(times))     if times else 0.0

        print(f"--- Sample {i}/{sample_count}: {s} â†’ {g} ìš”ì•½ ---")
        print(f"  ì‹œë„ íšŸìˆ˜  : {repeats}")
        print(f"  ì„±ê³µ íšŸìˆ˜  : {success}")
        print(f"  í‰ê·  ì‹œê°„  : {mean_sec:.6f}ì´ˆ")
        print(f"  í‘œì¤€íŽ¸ì°¨   : {std_sec:.6f}ì´ˆ")
        print(f"  ìµœë‹¨ ì‹œê°„  : {best_sec:.6f}ì´ˆ")
        print(f"  ìµœìž¥ ì‹œê°„  : {worst_sec:.6f}ì´ˆ\n")

        summary_records.append({
            "start": s,
            "goal": g,
            "runs_attempted": repeats,
            "runs_successful": success,
            "mean_sec": mean_sec,
            "std_sec": std_sec,
            "best_sec": best_sec,
            "worst_sec": worst_sec
        })

    # â¸ CSV ì €ìž¥
    pd.DataFrame(detail_records).to_csv(detail_csv, index=False, encoding="utf-8-sig")
    pd.DataFrame(summary_records).to_csv(summary_csv, index=False, encoding="utf-8-sig")

    # â¹ ê¸€ë¡œë²Œ ìš”ì•½ ê³„ì‚°
    all_times = [rec["elapsed_sec"] for rec in detail_records]
    global_summary = {
        "total_runs":             len(all_times),
        "total_successful_runs":  sum(1 for rec in detail_records),
        "total_time_sec":         float(sum(all_times)),
        "mean_time_sec":          float(np.mean(all_times)) if all_times else 0.0,
        "std_time_sec":           float(np.std(all_times))  if all_times else 0.0,
        "best_time_sec":          float(min(all_times))     if all_times else 0.0,
        "worst_time_sec":         float(max(all_times))     if all_times else 0.0
    }

    # âº ê¸€ë¡œë²Œ ìš”ì•½ ì¶œë ¥
    print("=== ì „ì²´(Global) ìš”ì•½ ===")
    print(f"  ì‹œë„ ì´íšŸìˆ˜      : {global_summary['total_runs']}")
    print(f"  ì„±ê³µ ì´íšŸìˆ˜      : {global_summary['total_successful_runs']}")
    print(f"  ì „ì²´ ì†Œìš” ì‹œê°„  : {global_summary['total_time_sec']:.6f}ì´ˆ")
    print(f"  ì „ì²´ í‰ê·  ì‹œê°„  : {global_summary['mean_time_sec']:.6f}ì´ˆ")
    print(f"  ì „ì²´ í‘œì¤€íŽ¸ì°¨    : {global_summary['std_time_sec']:.6f}ì´ˆ")
    print(f"  ì „ì²´ ìµœë‹¨ ì‹œê°„  : {global_summary['best_time_sec']:.6f}ì´ˆ")
    print(f"  ì „ì²´ ìµœìž¥ ì‹œê°„  : {global_summary['worst_time_sec']:.6f}ì´ˆ\n")

    # â» ê¸€ë¡œë²Œ ìš”ì•½ CSV ì €ìž¥
    pd.DataFrame([global_summary]).to_csv(global_csv, index=False, encoding="utf-8-sig")

    return summary_records, global_summary

if __name__ == "__main__":
    random.seed(42)

    all_stations = generate_station_list()

    print("ðŸš€ 1000ê°œ ëžœë¤ ì¶œë°œ-ë„ì°© ìŒì— ëŒ€í•´ A* íƒìƒ‰ ì‹œìž‘")
    # perâ€sample summary ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    summary_records = analyse_1000_random_astar(all_stations, sample_count=100)
